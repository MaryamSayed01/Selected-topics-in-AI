{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3633f96-10cf-4fe3-8365-01c576914fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import exp,log,mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from numpy import log,dot,exp,shape,min,max,clip,mean,sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from tensorflow.keras import utils as np_utils\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "# np.random.set_state(42)\n",
    "random_state = 42\n",
    "np.random.state = random_state\n",
    "np.random.seed = random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee10723-598c-46d2-b402-7859e0993dff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Car Price Prediction \n",
    "```\n",
    "(Regression problem [first dataset])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b56311-0874-47d0-97cf-8e1a73caaebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "car_price=pd.read_csv('Car Price Prediction.csv')\n",
    "print(car_price.head())\n",
    "print(car_price.info())\n",
    "print(car_price.describe())\n",
    "print(car_price.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da57df-4138-45cf-b271-bd1eaa4dba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_price.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7335bf20-57ac-4684-8b4f-d0320e5b2ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tranform object type cols to int\n",
    "print(car_price.Fuel_Type.value_counts())\n",
    "print(car_price.Seller_Type.value_counts())\n",
    "print(car_price.Transmission.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6a9dd-d4a5-417b-b76b-790d8c48a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_price.Fuel_Type.replace({\"Petrol\":\"0\",\"Diesel\":\"1\",\"CNG\":\"2\"},inplace=True)\n",
    "car_price.Seller_Type.replace({\"Dealer\":\"0\",\"Individual\":\"1\"},inplace=True)\n",
    "car_price.Transmission.replace({\"Manual\":\"0\",\"Automatic\":\"1\"},inplace=True)\n",
    "car_price[[\"Fuel_Type\",\"Seller_Type\",\"Transmission\"]]=car_price[[\"Fuel_Type\",\"Seller_Type\",\"Transmission\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf44f0-6367-436c-affc-efe1d47b4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_car_price=car_price.Selling_Price\n",
    "X_car_price=car_price.drop([\"Selling_Price\",\"Car_Name\"],axis=1)\n",
    "X_car_price=np.array(X_car_price)\n",
    "y_car_price=np.array(y_car_price)\n",
    "\n",
    "X_train_1,X_test_1,y_train_1,y_test_1=train_test_split(X_car_price,y_car_price,test_size=0.2,random_state=42)\n",
    "print(\"x train: \",X_train_1.shape)\n",
    "print(\"x test: \",X_test_1.shape)\n",
    "print(\"y train: \",y_train_1.shape)\n",
    "print(\"y test: \",y_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f6612-02e8-477f-91bf-fefbe3a62918",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Breast cancer classification \n",
    "```\n",
    "(Classification problem [second dataset])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486da7a-2d37-4f75-849b-ac241f491323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(cancer.data,columns=cancer.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbc3e6-10a6-4429-a252-23bf4cb2c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123f2bd-19a5-4bd1-a389-192be4497984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd98d7-5329-47d7-b450-b55513db1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = pd.Series(cancer.target)\n",
    "X_train_2, X_test_2,y_train_2, y_test_2= train_test_split(X, y, test_size=0.20, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_2=np.array(X_train_2)\n",
    "X_test_2=np.array(X_test_2)\n",
    "y_train_2=np.array(y_train_2)\n",
    "y_test_2=np.array(y_test_2)\n",
    "y_train_2 = to_categorical(y_train_2, dtype =\"uint8\")\n",
    "y_test_2 = to_categorical(y_test_2, dtype =\"uint8\")\n",
    "print('X_train: ' + str(X_train_2.shape))\n",
    "print('Y_train: ' + str(y_train_2.shape))\n",
    "print('X_test:  '  + str(X_test_2.shape))\n",
    "print('Y_test:  '  + str(y_test_2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03283cb-e090-453e-808c-142ba636b7d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Neural Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ae335-2560-4914-a204-94017627b85c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implementing Layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ebd13-d5cc-4751-a09a-20a98908190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input_Layer:\n",
    "    def __init__(self,features,data):\n",
    "        self.neurons=features\n",
    "        self.input=data\n",
    "class Layer:\n",
    "    def __init__(self,n_input,n_neurons):\n",
    "        self.neurons=n_neurons\n",
    "        self.weights=(np.random.rand(n_input,n_neurons)-0.5)*sqrt(1/(n_input+n_neurons))\n",
    "    def forward(self,inputs):\n",
    "        self.input=inputs\n",
    "        self.output=np.dot(inputs,self.weights)\n",
    "    def backward(self,dvalues):\n",
    "        inputs=self.input.reshape(-1, 1)\n",
    "        self.dweights =  np.dot(inputs, dvalues)\n",
    "        # Gradient on values\n",
    "        self.dinputs  = np.dot(dvalues, self.weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256e82a-935b-4ef3-a813-4c54303703e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Implementing Activation functions to be used in NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11c06d-547c-4891-80b9-6ba8f4654486",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear :\n",
    "    def forward (self ,inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output  = inputs\n",
    "    def backward(self, dvalues):\n",
    "        self.dinputs  =  dvalues.copy()\n",
    "        \n",
    "class Sigmoid:\n",
    "    def forward(self,inputs):\n",
    "        inputs = np.float128(inputs)\n",
    "        self.output=(1/(1+exp(-inputs)))\n",
    "    def backward(self,dvalues=None):\n",
    "        self.dinputs =(1 - self.output) * self.output\n",
    "        \n",
    "class ReLU:\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.maximum(0,inputs)\n",
    "    def backward(self,outputs):\n",
    "        self.dinputs = outputs.copy()\n",
    "        self.dinputs[self.output <= 0] = 0\n",
    "        \n",
    "class Softmax:\n",
    "    def forward(self,inputs):\n",
    "        z=exp(inputs-np.max(inputs,axis=1,keepdims=True))\n",
    "        probs=z/np.sum(z,axis=1,keepdims=True)\n",
    "        self.output=probs\n",
    "    def backward(self,dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            jacobian_matrix = np.diagflat(single_output) -np.dot(single_output, single_output.T)\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,single_dvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fdada-e44d-4e45-8b77-591c490d0bbd",
   "metadata": {},
   "source": [
    "## Loss Functions Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba676cb-a34b-4a9c-9c0b-7b4470d3a9c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Regression loss Mean Sqaure Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bda304-a897-4cc9-8412-094804e2d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    def forward(self,y,y_hat):\n",
    "        self.output=mean((y_hat-y)**2,axis=-1)\n",
    "        self.error=mean((y_hat-y)**2)\n",
    "    def backward(self,dvals,y):\n",
    "        samples = len(dvals)\n",
    "        # outputs = len(dvals[0])\n",
    "        self.dinputs = -2 * (y - dvals) / samples\n",
    "        self.dinputs = self.dinputs / samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37278a4d-cb29-47c1-beaf-98914f0c49ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Regression structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29593fa-6cf0-45c7-9999-cd26bffd3890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_neurons=20\n",
    "eta=0.07\n",
    "epochs=5000\n",
    "#input layer\n",
    "layer0=Input_Layer(X_train_1.shape[1],X_train_1)\n",
    "#hidden layer\n",
    "layer1=Layer(layer0.neurons,n_neurons)\n",
    "activation1=Sigmoid()\n",
    "#output layer\n",
    "layer2=Layer(layer1.neurons,1)\n",
    "activation2=Linear()\n",
    "for epoch in range(epochs):\n",
    "    y_pred=[]\n",
    "    for x,y in zip(X_train_1,y_train_1):\n",
    "        #Forward Path\n",
    "        layer1.forward(x)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "        y_pred.append(activation2.output)\n",
    "        loss=MSE()\n",
    "        loss.forward(y,activation2.output)\n",
    "        #backward Path\n",
    "        activation2.backward(layer2.output)\n",
    "        dinputs2=activation2.dinputs\n",
    "        layer2.backward(dinputs2)\n",
    "        activation1.backward(layer1.output)\n",
    "        dinputs1=activation1.dinputs.reshape(-1,1)\n",
    "        layer1.backward(dinputs1.T)\n",
    "        layer1.weights += (-eta* layer1.dweights)*0.5\n",
    "        layer2.dweights=layer2.dweights.reshape(-1,1)\n",
    "        layer2.weights += (-eta* layer2.dweights)\n",
    "        layer1.weights=(layer1.weights-min(layer1.weights))/(max(layer1.weights)-min(layer1.weights))\n",
    "        layer2.weights=(layer2.weights-min(layer2.weights))/(max(layer2.weights)-min(layer2.weights))\n",
    "    if epoch%500==0:\n",
    "        y_pred=np.array(y_pred)\n",
    "        loss_=MSE()\n",
    "        loss_.forward(y_train_1,y_pred)\n",
    "        print('Loss in epoch{}'.format(epoch),loss_.error)\n",
    "    if epoch%1000==0:\n",
    "        print('layer1.weights',layer1.weights)                        \n",
    "        print('layer2.weights',layer2.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ac0e7-0f67-45db-96ea-741ab8274898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights1=layer1.weights\n",
    "weights2=layer2.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db360899-fe9a-4a28-ad95-dd196990ddde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(X,layer1,layer2,activation1,activation2):\n",
    "    y_pred=[]\n",
    "    for x in X:\n",
    "        layer1.forward(x)\n",
    "        activation1.forward(layer1.output)\n",
    "        layer2.forward(activation1.output)\n",
    "        activation2.forward(layer2.output)\n",
    "        y_pred.append(activation2.output)\n",
    "    return np.array(y_pred)\n",
    "def accuracy(y,y_hat,regression=True):\n",
    "    if regression:\n",
    "        loss=MSE()\n",
    "        loss.forward(y,y_hat)\n",
    "        return loss.error\n",
    "    else:\n",
    "        length=y.shape[0]\n",
    "        right=0\n",
    "        for y,y_hat in zip(y,y_pred):\n",
    "            if (y==y_hat ).all():\n",
    "                rights+=1\n",
    "        return right/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f85aab-99cb-4488-94bb-c06cb0eee98e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_1=predict(X_test_1,layer1,layer2,activation1,activation2)\n",
    "acc_1=accuracy(y_test_1,y_pred_1)\n",
    "acc_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b194bd-ded4-41ba-8d7b-c9eb68c773ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classification Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400a684-36a2-430f-b510-e4446de8256c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self,inputs):\n",
    "        inputs = np.float128(inputs)\n",
    "        self.output=(1/(1+exp(-inputs)))\n",
    "    def backward(self,dvalues=None):\n",
    "        self.dinputs =(1 - self.output) * self.output\n",
    "        \n",
    "class ReLU:\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.maximum(0,inputs)\n",
    "    def backward(self,outputs):\n",
    "        self.dinputs = outputs.copy()\n",
    "        self.dinputs[self.output <= 0] = 0\n",
    "        \n",
    "class Softmax:\n",
    "    def forward(self,inputs):\n",
    "        z=exp(inputs-np.max(inputs,axis=1,keepdims=True))\n",
    "        probs=z/np.sum(z,axis=1,keepdims=True)\n",
    "        self.output=probs\n",
    "    def backward(self,dvalues):\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "            jacobian_matrix = np.diagflat(single_output) -np.dot(single_output, single_output.T)\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,single_dvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff285d1-2865-4ab3-b735-f0c149d68ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Binary cross-entropy loss\n",
    "class Loss_BinaryCrossentropy:\n",
    "    def forward (self,y_pred,y_true ):\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = clip(y_pred,1e-7,1-1e-7 )\n",
    "        # Calculate sample-wise loss\n",
    "        sample_losses  = - (y_true *log(y_pred_clipped) +(1-y_true)* log( 1 - y_pred_clipped))\n",
    "        sample_losses  = mean(sample_losses,  axis =- 1 )\n",
    "        self.error=sample_losses\n",
    "        return sample_losses\n",
    "    def backward(  self , dvalues,y_true ):\n",
    "        samples = len(dvalues)\n",
    "        outputs =  len (dvalues[0])\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        clipped_dvalues =clip(dvalues, 1e-7, 1  - 1e-7 )\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -(y_true /clipped_dvalues -( 1 - y_true)/(  1  -  clipped_dvalues))/outputs\n",
    "        # Normalize gradient\n",
    "        self.dinputs =  self.dinputs/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7375e-0043-4b4e-86f5-7929d336c37a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_neurons=20\n",
    "eta=0.01\n",
    "epochs=5000\n",
    "#input layer\n",
    "layer0_0=Input_Layer(X_train_2.shape[1],X_train_2)\n",
    "#hidden layer\n",
    "layer1_1=Layer(layer0_0.neurons,n_neurons)\n",
    "activation1_1=Sigmoid()\n",
    "#output layer\n",
    "layer2_1=Layer(layer1.neurons,2)\n",
    "activation2_1=Sigmoid()\n",
    "for epoch in range(epochs):\n",
    "    y_pred=[]\n",
    "    for x,y in zip(X_train_2,y_train_2):\n",
    "        #Forward Path\n",
    "        layer1_1.forward(x)\n",
    "        activation1_1.forward(layer1_1.output)\n",
    "        layer2_1.forward(activation1_1.output)\n",
    "        activation2_1.forward(layer2_1.output)\n",
    "        y_pred.append(activation2_1.output)\n",
    "        loss=Loss_BinaryCrossentropy()\n",
    "        loss.forward(activation2_1.output,y)\n",
    "        #backward Path\n",
    "        activation2_1.backward(layer2_1.output)\n",
    "        dinputs2=activation2_1.dinputs.reshape(-1,1)\n",
    "        layer2_1.backward(dinputs2.T)\n",
    "        activation1_1.backward(layer1_1.output)\n",
    "        dinputs1=activation1_1.dinputs.reshape(-1,1)\n",
    "        layer1_1.backward(dinputs1.T)\n",
    "        \n",
    "        layer1_1.weights += (-eta* layer1_1.dweights)*0.5\n",
    "        # layer2_1.dweights=layer2_1.dweights.reshape(-1,1)\n",
    "        layer2_1.weights += (-eta* layer2_1.dweights)\n",
    "        layer1_1.weights = layer1_1.weights/ layer1_1.weights.max() \n",
    "        layer2_1.weights = layer2_1.weights/ layer2_1.weights.max()\n",
    "        \n",
    "    if epoch%500==0:\n",
    "        print(y_pred)\n",
    "        y_pred=np.array(y_pred)\n",
    "        y_pred=np.ceil(y_pred)\n",
    "        loss_=Loss_BinaryCrossentropy()\n",
    "        loss_.forward(y_pred,y_train_2)\n",
    "        # print(y_pred)\n",
    "        print('Loss in epoch{}'.format(epoch),loss_.error)\n",
    "    # if epoch%1000==0:\n",
    "    #     print('layer1.weights',layer1_1.weights)                        \n",
    "    #     print('layer2_1.weights',layer2_1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac42548-da2e-46cc-aaa3-9ba6c1f31e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_2=predict(X_test_2,layer1_1,layer2_1,activation1_1,activation2_1)\n",
    "y_pred_2=np.ceil(y_pred_2)\n",
    "\n",
    "acc_2=accuracy(y_test_2,y_pred_2,regression=False)\n",
    "acc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5413b-9ad0-474a-a2ef-cf9e68b88c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
